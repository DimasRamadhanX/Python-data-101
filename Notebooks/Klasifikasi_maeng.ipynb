{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier as RFE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from joblib import Parallel, delayed\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"https://media.githubusercontent.com/media/DimasRamadhanX/Python-data-101/refs/heads/main/PAP%20C/df_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Date Rptd','DATE OCC','Crm Cd Desc','Mocodes','Vict Age','Weapon Used Cd','LOCATION','Status Desc','Crm Cd 1','Crm Cd 2','Crm Cd 3','Crm Cd 4','Premis Cd'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Premis Desc</th>\n",
       "      <th>Weapon Desc</th>\n",
       "      <th>Status</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_name</th>\n",
       "      <th>month_name</th>\n",
       "      <th>Vict Sex_F</th>\n",
       "      <th>Vict Sex_M</th>\n",
       "      <th>Vict Sex_X</th>\n",
       "      <th>Vict Descent_A</th>\n",
       "      <th>Vict Descent_B</th>\n",
       "      <th>Vict Descent_C</th>\n",
       "      <th>Vict Descent_D</th>\n",
       "      <th>Vict Descent_F</th>\n",
       "      <th>Vict Descent_G</th>\n",
       "      <th>Vict Descent_H</th>\n",
       "      <th>Vict Descent_I</th>\n",
       "      <th>Vict Descent_J</th>\n",
       "      <th>Vict Descent_K</th>\n",
       "      <th>Vict Descent_L</th>\n",
       "      <th>Vict Descent_O</th>\n",
       "      <th>Vict Descent_P</th>\n",
       "      <th>Vict Descent_S</th>\n",
       "      <th>Vict Descent_U</th>\n",
       "      <th>Vict Descent_V</th>\n",
       "      <th>Vict Descent_W</th>\n",
       "      <th>Vict Descent_X</th>\n",
       "      <th>Vict Descent_Z</th>\n",
       "      <th>AgeStd</th>\n",
       "      <th>season</th>\n",
       "      <th>night-day</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2130</td>\n",
       "      <td>510</td>\n",
       "      <td>STREET</td>\n",
       "      <td>No Weapon</td>\n",
       "      <td>AA</td>\n",
       "      <td>34.0375</td>\n",
       "      <td>-118.3506</td>\n",
       "      <td>21</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>March</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.329626</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Night</td>\n",
       "      <td>Other Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>330</td>\n",
       "      <td>BUS STOP/LAYOVER (ALSO QUERY 124)</td>\n",
       "      <td>No Weapon</td>\n",
       "      <td>IC</td>\n",
       "      <td>34.0444</td>\n",
       "      <td>-118.2628</td>\n",
       "      <td>18</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>February</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812370</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Night</td>\n",
       "      <td>Downtown Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1700</td>\n",
       "      <td>480</td>\n",
       "      <td>MULTI-UNIT DWELLING (APARTMENT, DUPLEX, ETC)</td>\n",
       "      <td>No Weapon</td>\n",
       "      <td>IC</td>\n",
       "      <td>34.0210</td>\n",
       "      <td>-118.3002</td>\n",
       "      <td>17</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>November</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.463713</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Day</td>\n",
       "      <td>Other Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2037</td>\n",
       "      <td>343</td>\n",
       "      <td>CLOTHING STORE</td>\n",
       "      <td>No Weapon</td>\n",
       "      <td>IC</td>\n",
       "      <td>34.1576</td>\n",
       "      <td>-118.4387</td>\n",
       "      <td>20</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>March</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.463713</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Night</td>\n",
       "      <td>San Fernando Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200</td>\n",
       "      <td>354</td>\n",
       "      <td>SIDEWALK</td>\n",
       "      <td>No Weapon</td>\n",
       "      <td>IC</td>\n",
       "      <td>34.0944</td>\n",
       "      <td>-118.3277</td>\n",
       "      <td>12</td>\n",
       "      <td>Monday</td>\n",
       "      <td>August</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.053543</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Day</td>\n",
       "      <td>Other Region</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TIME OCC  Crm Cd                                   Premis Desc Weapon Desc  \\\n",
       "0      2130     510                                        STREET   No Weapon   \n",
       "1      1800     330             BUS STOP/LAYOVER (ALSO QUERY 124)   No Weapon   \n",
       "2      1700     480  MULTI-UNIT DWELLING (APARTMENT, DUPLEX, ETC)   No Weapon   \n",
       "3      2037     343                                CLOTHING STORE   No Weapon   \n",
       "4      1200     354                                      SIDEWALK   No Weapon   \n",
       "\n",
       "  Status      LAT       LON  hour   day_name month_name  Vict Sex_F  \\\n",
       "0     AA  34.0375 -118.3506    21     Sunday      March         0.0   \n",
       "1     IC  34.0444 -118.2628    18   Saturday   February         0.0   \n",
       "2     IC  34.0210 -118.3002    17  Wednesday   November         0.0   \n",
       "3     IC  34.1576 -118.4387    20    Tuesday      March         0.0   \n",
       "4     IC  34.0944 -118.3277    12     Monday     August         0.0   \n",
       "\n",
       "   Vict Sex_M  Vict Sex_X  Vict Descent_A  Vict Descent_B  Vict Descent_C  \\\n",
       "0         1.0         0.0             0.0             0.0             0.0   \n",
       "1         1.0         0.0             0.0             0.0             0.0   \n",
       "2         0.0         1.0             0.0             0.0             0.0   \n",
       "3         1.0         0.0             0.0             0.0             0.0   \n",
       "4         1.0         0.0             0.0             0.0             0.0   \n",
       "\n",
       "   Vict Descent_D  Vict Descent_F  Vict Descent_G  Vict Descent_H  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             1.0   \n",
       "\n",
       "   Vict Descent_I  Vict Descent_J  Vict Descent_K  Vict Descent_L  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   Vict Descent_O  Vict Descent_P  Vict Descent_S  Vict Descent_U  \\\n",
       "0             1.0             0.0             0.0             0.0   \n",
       "1             1.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             1.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   Vict Descent_V  Vict Descent_W  Vict Descent_X  Vict Descent_Z    AgeStd  \\\n",
       "0             0.0             0.0             0.0             0.0 -1.329626   \n",
       "1             0.0             0.0             0.0             0.0  0.812370   \n",
       "2             0.0             0.0             1.0             0.0 -0.463713   \n",
       "3             0.0             0.0             0.0             0.0 -0.463713   \n",
       "4             0.0             0.0             0.0             0.0 -0.053543   \n",
       "\n",
       "   season night-day                Region  \n",
       "0  Winter     Night          Other Region  \n",
       "1  Winter     Night  Downtown Los Angeles  \n",
       "2    Fall       Day          Other Region  \n",
       "3  Winter     Night   San Fernando Valley  \n",
       "4  Summer       Day          Other Region  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crm Cd\n",
       "510    107703\n",
       "624     73671\n",
       "330     60486\n",
       "354     59770\n",
       "740     58764\n",
       "        ...  \n",
       "884         4\n",
       "906         4\n",
       "445         4\n",
       "926         1\n",
       "453         1\n",
       "Name: count, Length: 140, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = df['Crm Cd'].value_counts()\n",
    "class_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col]).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi OneHotEncoder\n",
    "# Assume df is your original DataFrame\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit and transform the specified columns\n",
    "encoded_features = encoder.fit_transform(df[['day_name', 'month_name', 'Status', 'season', 'Region']])\n",
    "\n",
    "# Create DataFrame with encoded features\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_features,\n",
    "    columns=encoder.get_feature_names_out(['day_name', 'month_name', 'Status', 'season', 'Region'])\n",
    ")\n",
    "\n",
    "# Convert all encoded columns to int8\n",
    "encoded_df = encoded_df.astype('int8')\n",
    "\n",
    "# Combine with original DataFrame and drop original columns\n",
    "df = pd.concat(\n",
    "    [df.reset_index(drop=True), encoded_df],\n",
    "    axis=1\n",
    ").drop(columns=['day_name', 'month_name', 'Status', 'season', 'Region'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour']=df['hour'].astype('int8')\n",
    "df['TIME OCC']=df['TIME OCC'].astype('int16')\n",
    "df['Crm Cd']=df['Crm Cd'].astype('int16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in df.columns:\n",
    "    if col.startswith(\"Vict\"):\n",
    "        df[col] = df[col].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 964311 entries, 0 to 964310\n",
      "Data columns (total 63 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   TIME OCC        964311 non-null  int16  \n",
      " 1   Crm Cd          964311 non-null  int16  \n",
      " 2   Premis Desc     964311 non-null  int16  \n",
      " 3   Weapon Desc     964311 non-null  int16  \n",
      " 4   LAT             964311 non-null  float64\n",
      " 5   LON             964311 non-null  float64\n",
      " 6   hour            964311 non-null  int8   \n",
      " 7   Vict Sex_F      964311 non-null  int8   \n",
      " 8   Vict Sex_M      964311 non-null  int8   \n",
      " 9   Vict Sex_X      964311 non-null  int8   \n",
      " 10  Vict Descent_A  964311 non-null  int8   \n",
      " 11  Vict Descent_B  964311 non-null  int8   \n",
      " 12  Vict Descent_C  964311 non-null  int8   \n",
      " 13  Vict Descent_D  964311 non-null  int8   \n",
      " 14  Vict Descent_F  964311 non-null  int8   \n",
      " 15  Vict Descent_G  964311 non-null  int8   \n",
      " 16  Vict Descent_H  964311 non-null  int8   \n",
      " 17  Vict Descent_I  964311 non-null  int8   \n",
      " 18  Vict Descent_J  964311 non-null  int8   \n",
      " 19  Vict Descent_K  964311 non-null  int8   \n",
      " 20  Vict Descent_L  964311 non-null  int8   \n",
      " 21  Vict Descent_O  964311 non-null  int8   \n",
      " 22  Vict Descent_P  964311 non-null  int8   \n",
      " 23  Vict Descent_S  964311 non-null  int8   \n",
      " 24  Vict Descent_U  964311 non-null  int8   \n",
      " 25  Vict Descent_V  964311 non-null  int8   \n",
      " 26  Vict Descent_W  964311 non-null  int8   \n",
      " 27  Vict Descent_X  964311 non-null  int8   \n",
      " 28  Vict Descent_Z  964311 non-null  int8   \n",
      " 29  AgeStd          964311 non-null  float64\n",
      " 30  night-day       964311 non-null  int16  \n",
      " 31  day_name_1      964311 non-null  int8   \n",
      " 32  day_name_2      964311 non-null  int8   \n",
      " 33  day_name_3      964311 non-null  int8   \n",
      " 34  day_name_4      964311 non-null  int8   \n",
      " 35  day_name_5      964311 non-null  int8   \n",
      " 36  day_name_6      964311 non-null  int8   \n",
      " 37  month_name_1    964311 non-null  int8   \n",
      " 38  month_name_2    964311 non-null  int8   \n",
      " 39  month_name_3    964311 non-null  int8   \n",
      " 40  month_name_4    964311 non-null  int8   \n",
      " 41  month_name_5    964311 non-null  int8   \n",
      " 42  month_name_6    964311 non-null  int8   \n",
      " 43  month_name_7    964311 non-null  int8   \n",
      " 44  month_name_8    964311 non-null  int8   \n",
      " 45  month_name_9    964311 non-null  int8   \n",
      " 46  month_name_10   964311 non-null  int8   \n",
      " 47  month_name_11   964311 non-null  int8   \n",
      " 48  Status_1        964311 non-null  int8   \n",
      " 49  Status_2        964311 non-null  int8   \n",
      " 50  Status_3        964311 non-null  int8   \n",
      " 51  Status_4        964311 non-null  int8   \n",
      " 52  Status_5        964311 non-null  int8   \n",
      " 53  season_1        964311 non-null  int8   \n",
      " 54  season_2        964311 non-null  int8   \n",
      " 55  season_3        964311 non-null  int8   \n",
      " 56  season_4        964311 non-null  int8   \n",
      " 57  Region_1        964311 non-null  int8   \n",
      " 58  Region_2        964311 non-null  int8   \n",
      " 59  Region_3        964311 non-null  int8   \n",
      " 60  Region_4        964311 non-null  int8   \n",
      " 61  Region_5        964311 non-null  int8   \n",
      " 62  Region_6        964311 non-null  int8   \n",
      "dtypes: float64(3), int16(5), int8(55)\n",
      "memory usage: 81.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crm Cd\n",
       "510    107703\n",
       "624     73671\n",
       "330     60486\n",
       "354     59770\n",
       "740     58764\n",
       "        ...  \n",
       "884         4\n",
       "906         4\n",
       "445         4\n",
       "926         1\n",
       "453         1\n",
       "Name: count, Length: 140, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Crm Cd'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "intdf=df[['TIME OCC', 'Premis Desc', 'Weapon Desc','LAT','LON','hour','AgeStd','night-day']]\n",
    "corr = intdf.corr('spearman')\n",
    "sns.heatmap(corr,\n",
    "            annot = np.where(np.abs(corr)>0.75,'S', # correlation more than +/- 75% labelled as 'STRONG CORRELATION'\n",
    "                      np.where(np.abs(corr)>0.5,'M', # correlation more than +/- 50% labelled as 'MEDIUM CORRELATION'\n",
    "                           np.where(np.abs(corr)>0.25,'W',''))), # correlation more than +/- 25% labelled as 'WEAK CORRELATION'\n",
    "            mask=np.triu(np.ones_like(corr, dtype=bool)),\n",
    "            square=True,\n",
    "            center=0,fmt='', linewidths=.5,\n",
    "            cmap=\"vlag\", cbar_kws={\"shrink\": 0.8}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Premis Desc</th>\n",
       "      <th>Weapon Desc</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>hour</th>\n",
       "      <th>Vict Sex_F</th>\n",
       "      <th>Vict Sex_M</th>\n",
       "      <th>Vict Sex_X</th>\n",
       "      <th>Vict Descent_A</th>\n",
       "      <th>Vict Descent_B</th>\n",
       "      <th>Vict Descent_C</th>\n",
       "      <th>Vict Descent_D</th>\n",
       "      <th>Vict Descent_F</th>\n",
       "      <th>Vict Descent_G</th>\n",
       "      <th>Vict Descent_H</th>\n",
       "      <th>Vict Descent_I</th>\n",
       "      <th>Vict Descent_J</th>\n",
       "      <th>Vict Descent_K</th>\n",
       "      <th>Vict Descent_L</th>\n",
       "      <th>Vict Descent_O</th>\n",
       "      <th>Vict Descent_P</th>\n",
       "      <th>Vict Descent_S</th>\n",
       "      <th>Vict Descent_U</th>\n",
       "      <th>Vict Descent_V</th>\n",
       "      <th>Vict Descent_W</th>\n",
       "      <th>Vict Descent_X</th>\n",
       "      <th>Vict Descent_Z</th>\n",
       "      <th>AgeStd</th>\n",
       "      <th>night-day</th>\n",
       "      <th>day_name_1</th>\n",
       "      <th>day_name_2</th>\n",
       "      <th>day_name_3</th>\n",
       "      <th>day_name_4</th>\n",
       "      <th>day_name_5</th>\n",
       "      <th>day_name_6</th>\n",
       "      <th>month_name_1</th>\n",
       "      <th>month_name_2</th>\n",
       "      <th>month_name_3</th>\n",
       "      <th>month_name_4</th>\n",
       "      <th>month_name_5</th>\n",
       "      <th>month_name_6</th>\n",
       "      <th>month_name_7</th>\n",
       "      <th>month_name_8</th>\n",
       "      <th>month_name_9</th>\n",
       "      <th>month_name_10</th>\n",
       "      <th>month_name_11</th>\n",
       "      <th>Status_1</th>\n",
       "      <th>Status_2</th>\n",
       "      <th>Status_3</th>\n",
       "      <th>Status_4</th>\n",
       "      <th>Status_5</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>season_4</th>\n",
       "      <th>Region_1</th>\n",
       "      <th>Region_2</th>\n",
       "      <th>Region_3</th>\n",
       "      <th>Region_4</th>\n",
       "      <th>Region_5</th>\n",
       "      <th>Region_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>266</td>\n",
       "      <td>42</td>\n",
       "      <td>34.0375</td>\n",
       "      <td>-118.3506</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.329626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>330</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>34.0444</td>\n",
       "      <td>-118.2628</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812370</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>480</td>\n",
       "      <td>207</td>\n",
       "      <td>42</td>\n",
       "      <td>34.0210</td>\n",
       "      <td>-118.3002</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.463713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>34.1576</td>\n",
       "      <td>-118.4387</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.463713</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>354</td>\n",
       "      <td>254</td>\n",
       "      <td>42</td>\n",
       "      <td>34.0944</td>\n",
       "      <td>-118.3277</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053543</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964306</th>\n",
       "      <td>510</td>\n",
       "      <td>266</td>\n",
       "      <td>42</td>\n",
       "      <td>34.0362</td>\n",
       "      <td>-118.3284</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.329626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964307</th>\n",
       "      <td>745</td>\n",
       "      <td>97</td>\n",
       "      <td>76</td>\n",
       "      <td>34.0685</td>\n",
       "      <td>-118.2460</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.329626</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964308</th>\n",
       "      <td>888</td>\n",
       "      <td>158</td>\n",
       "      <td>42</td>\n",
       "      <td>34.2500</td>\n",
       "      <td>-118.5990</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.329626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964309</th>\n",
       "      <td>230</td>\n",
       "      <td>254</td>\n",
       "      <td>64</td>\n",
       "      <td>34.0215</td>\n",
       "      <td>-118.2868</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.860581</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964310</th>\n",
       "      <td>510</td>\n",
       "      <td>227</td>\n",
       "      <td>42</td>\n",
       "      <td>34.1961</td>\n",
       "      <td>-118.4510</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.329626</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964311 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Crm Cd  Premis Desc  Weapon Desc      LAT       LON  hour  Vict Sex_F  \\\n",
       "0          510          266           42  34.0375 -118.3506    21           0   \n",
       "1          330           29           42  34.0444 -118.2628    18           0   \n",
       "2          480          207           42  34.0210 -118.3002    17           0   \n",
       "3          343           40           42  34.1576 -118.4387    20           0   \n",
       "4          354          254           42  34.0944 -118.3277    12           0   \n",
       "...        ...          ...          ...      ...       ...   ...         ...   \n",
       "964306     510          266           42  34.0362 -118.3284    14           0   \n",
       "964307     745           97           76  34.0685 -118.2460     1           0   \n",
       "964308     888          158           42  34.2500 -118.5990     7           0   \n",
       "964309     230          254           64  34.0215 -118.2868    15           0   \n",
       "964310     510          227           42  34.1961 -118.4510    23           0   \n",
       "\n",
       "        Vict Sex_M  Vict Sex_X  Vict Descent_A  Vict Descent_B  \\\n",
       "0                1           0               0               0   \n",
       "1                1           0               0               0   \n",
       "2                0           1               0               0   \n",
       "3                1           0               0               0   \n",
       "4                1           0               0               0   \n",
       "...            ...         ...             ...             ...   \n",
       "964306           0           0               0               0   \n",
       "964307           0           0               0               0   \n",
       "964308           0           0               0               0   \n",
       "964309           0           0               0               0   \n",
       "964310           0           0               0               0   \n",
       "\n",
       "        Vict Descent_C  Vict Descent_D  Vict Descent_F  Vict Descent_G  \\\n",
       "0                    0               0               0               0   \n",
       "1                    0               0               0               0   \n",
       "2                    0               0               0               0   \n",
       "3                    0               0               0               0   \n",
       "4                    0               0               0               0   \n",
       "...                ...             ...             ...             ...   \n",
       "964306               0               0               0               0   \n",
       "964307               0               0               0               0   \n",
       "964308               0               0               0               0   \n",
       "964309               0               0               0               0   \n",
       "964310               0               0               0               0   \n",
       "\n",
       "        Vict Descent_H  Vict Descent_I  Vict Descent_J  Vict Descent_K  \\\n",
       "0                    0               0               0               0   \n",
       "1                    0               0               0               0   \n",
       "2                    0               0               0               0   \n",
       "3                    0               0               0               0   \n",
       "4                    1               0               0               0   \n",
       "...                ...             ...             ...             ...   \n",
       "964306               0               0               0               0   \n",
       "964307               0               0               0               0   \n",
       "964308               0               0               0               0   \n",
       "964309               0               0               0               0   \n",
       "964310               0               0               0               0   \n",
       "\n",
       "        Vict Descent_L  Vict Descent_O  Vict Descent_P  Vict Descent_S  \\\n",
       "0                    0               1               0               0   \n",
       "1                    0               1               0               0   \n",
       "2                    0               0               0               0   \n",
       "3                    0               1               0               0   \n",
       "4                    0               0               0               0   \n",
       "...                ...             ...             ...             ...   \n",
       "964306               0               0               0               0   \n",
       "964307               0               0               0               0   \n",
       "964308               0               0               0               0   \n",
       "964309               0               0               0               0   \n",
       "964310               0               0               0               0   \n",
       "\n",
       "        Vict Descent_U  Vict Descent_V  Vict Descent_W  Vict Descent_X  \\\n",
       "0                    0               0               0               0   \n",
       "1                    0               0               0               0   \n",
       "2                    0               0               0               1   \n",
       "3                    0               0               0               0   \n",
       "4                    0               0               0               0   \n",
       "...                ...             ...             ...             ...   \n",
       "964306               0               0               0               0   \n",
       "964307               0               0               0               0   \n",
       "964308               0               0               0               0   \n",
       "964309               0               0               0               0   \n",
       "964310               0               0               0               0   \n",
       "\n",
       "        Vict Descent_Z    AgeStd  night-day  day_name_1  day_name_2  \\\n",
       "0                    0 -1.329626          1           0           0   \n",
       "1                    0  0.812370          1           0           1   \n",
       "2                    0 -0.463713          0           0           0   \n",
       "3                    0 -0.463713          1           0           0   \n",
       "4                    0 -0.053543          0           1           0   \n",
       "...                ...       ...        ...         ...         ...   \n",
       "964306               0 -1.329626          0           0           0   \n",
       "964307               0 -1.329626          1           1           0   \n",
       "964308               0 -1.329626          0           0           0   \n",
       "964309               0  1.860581          0           0           0   \n",
       "964310               0 -1.329626          1           1           0   \n",
       "\n",
       "        day_name_3  day_name_4  day_name_5  day_name_6  month_name_1  \\\n",
       "0                1           0           0           0             0   \n",
       "1                0           0           0           0             0   \n",
       "2                0           0           0           1             0   \n",
       "3                0           0           1           0             0   \n",
       "4                0           0           0           0             1   \n",
       "...            ...         ...         ...         ...           ...   \n",
       "964306           0           0           1           0             0   \n",
       "964307           0           0           0           0             0   \n",
       "964308           0           0           0           0             0   \n",
       "964309           0           0           0           1             0   \n",
       "964310           0           0           0           0             1   \n",
       "\n",
       "        month_name_2  month_name_3  month_name_4  month_name_5  month_name_6  \\\n",
       "0                  0             0             0             0             0   \n",
       "1                  0             1             0             0             0   \n",
       "2                  0             0             0             0             0   \n",
       "3                  0             0             0             0             0   \n",
       "4                  0             0             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "964306             0             0             0             1             0   \n",
       "964307             0             0             1             0             0   \n",
       "964308             0             0             0             1             0   \n",
       "964309             0             0             0             0             0   \n",
       "964310             0             0             0             0             0   \n",
       "\n",
       "        month_name_7  month_name_8  month_name_9  month_name_10  \\\n",
       "0                  1             0             0              0   \n",
       "1                  0             0             0              0   \n",
       "2                  0             0             1              0   \n",
       "3                  1             0             0              0   \n",
       "4                  0             0             0              0   \n",
       "...              ...           ...           ...            ...   \n",
       "964306             0             0             0              0   \n",
       "964307             0             0             0              0   \n",
       "964308             0             0             0              0   \n",
       "964309             0             0             0              0   \n",
       "964310             0             0             0              0   \n",
       "\n",
       "        month_name_11  Status_1  Status_2  Status_3  Status_4  Status_5  \\\n",
       "0                   0         0         0         0         0         0   \n",
       "1                   0         0         0         1         0         0   \n",
       "2                   0         0         0         1         0         0   \n",
       "3                   0         0         0         1         0         0   \n",
       "4                   0         0         0         1         0         0   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "964306              0         0         0         1         0         0   \n",
       "964307              0         0         0         1         0         0   \n",
       "964308              0         0         0         1         0         0   \n",
       "964309              0         0         0         1         0         0   \n",
       "964310              0         0         0         1         0         0   \n",
       "\n",
       "        season_1  season_2  season_3  season_4  Region_1  Region_2  Region_3  \\\n",
       "0              0         0         1         0         0         0         1   \n",
       "1              0         0         1         0         0         0         0   \n",
       "2              0         0         0         0         0         0         1   \n",
       "3              0         0         1         0         0         0         0   \n",
       "4              0         1         0         0         0         0         1   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "964306         0         1         0         0         0         0         1   \n",
       "964307         0         0         1         0         0         0         1   \n",
       "964308         0         1         0         0         0         0         0   \n",
       "964309         1         0         0         0         0         0         0   \n",
       "964310         0         1         0         0         0         0         0   \n",
       "\n",
       "        Region_4  Region_5  Region_6  \n",
       "0              0         0         0  \n",
       "1              0         0         0  \n",
       "2              0         0         0  \n",
       "3              1         0         0  \n",
       "4              0         0         0  \n",
       "...          ...       ...       ...  \n",
       "964306         0         0         0  \n",
       "964307         0         0         0  \n",
       "964308         1         0         0  \n",
       "964309         0         0         0  \n",
       "964310         1         0         0  \n",
       "\n",
       "[964311 rows x 62 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('TIME OCC',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['Crm Cd'].value_counts()\n",
    "\n",
    "# Pilih kelas-kelas yang memiliki jumlah sampel di atas threshold\n",
    "relevant_classes = class_counts[class_counts >= 10].index\n",
    "\n",
    "# Filter dataset untuk hanya menyisakan kelas yang relevan\n",
    "df = df[df['Crm Cd'].isin(relevant_classes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Crm Cd\"])\n",
    "y = df[\"Crm Cd\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung jumlah sampel setiap kelas\n",
    "class_counts = y.value_counts()\n",
    "\n",
    "# Mengatur sampling_strategy untuk memastikan setidaknya 500 sampel per kelas\n",
    "sampling_strategy = {int(label): int(min(count, 500)) for label, count in class_counts.items()}\n",
    "\n",
    "# Inisialisasi dan terapkan RandomUnderSampler\n",
    "undersampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X, y= undersampler.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crm Cd\n",
      "110    500\n",
      "480    500\n",
      "761    500\n",
      "753    500\n",
      "745    500\n",
      "740    500\n",
      "668    500\n",
      "664    500\n",
      "662    500\n",
      "661    500\n",
      "121    500\n",
      "649    500\n",
      "648    500\n",
      "647    500\n",
      "627    500\n",
      "626    500\n",
      "625    500\n",
      "624    500\n",
      "623    500\n",
      "522    500\n",
      "520    500\n",
      "762    500\n",
      "763    500\n",
      "810    500\n",
      "890    500\n",
      "946    500\n",
      "940    500\n",
      "930    500\n",
      "910    500\n",
      "903    500\n",
      "902    500\n",
      "901    500\n",
      "900    500\n",
      "888    500\n",
      "812    500\n",
      "886    500\n",
      "860    500\n",
      "850    500\n",
      "845    500\n",
      "821    500\n",
      "820    500\n",
      "815    500\n",
      "813    500\n",
      "510    500\n",
      "956    500\n",
      "230    500\n",
      "352    500\n",
      "421    500\n",
      "420    500\n",
      "410    500\n",
      "331    500\n",
      "210    500\n",
      "310    500\n",
      "437    500\n",
      "251    500\n",
      "354    500\n",
      "440    500\n",
      "320    500\n",
      "341    500\n",
      "442    500\n",
      "237    500\n",
      "236    500\n",
      "235    500\n",
      "343    500\n",
      "350    500\n",
      "231    500\n",
      "220    500\n",
      "330    500\n",
      "928    476\n",
      "250    470\n",
      "441    468\n",
      "755    467\n",
      "822    467\n",
      "922    445\n",
      "932    376\n",
      "434    338\n",
      "666    320\n",
      "951    318\n",
      "122    315\n",
      "814    273\n",
      "438    269\n",
      "943    259\n",
      "622    239\n",
      "920    231\n",
      "933    200\n",
      "433    178\n",
      "439    176\n",
      "670    142\n",
      "806    136\n",
      "805    135\n",
      "660    116\n",
      "921    116\n",
      "487    114\n",
      "653    110\n",
      "351    108\n",
      "443    107\n",
      "450    103\n",
      "949     93\n",
      "654     92\n",
      "760     87\n",
      "950     75\n",
      "651     72\n",
      "954     41\n",
      "756     41\n",
      "353     38\n",
      "345     35\n",
      "652     27\n",
      "870     26\n",
      "944     24\n",
      "471     24\n",
      "474     22\n",
      "444     22\n",
      "882     17\n",
      "435     16\n",
      "470     16\n",
      "931     13\n",
      "451     13\n",
      "880     12\n",
      "347     12\n",
      "865     11\n",
      "436     10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_test= selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 964200 entries, 0 to 964310\n",
      "Data columns (total 63 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   TIME OCC        964200 non-null  int16  \n",
      " 1   Crm Cd          964200 non-null  int16  \n",
      " 2   Premis Desc     964200 non-null  int16  \n",
      " 3   Weapon Desc     964200 non-null  int16  \n",
      " 4   LAT             964200 non-null  float64\n",
      " 5   LON             964200 non-null  float64\n",
      " 6   hour            964200 non-null  int8   \n",
      " 7   Vict Sex_F      964200 non-null  float64\n",
      " 8   Vict Sex_M      964200 non-null  float64\n",
      " 9   Vict Sex_X      964200 non-null  float64\n",
      " 10  Vict Descent_A  964200 non-null  float64\n",
      " 11  Vict Descent_B  964200 non-null  float64\n",
      " 12  Vict Descent_C  964200 non-null  float64\n",
      " 13  Vict Descent_D  964200 non-null  float64\n",
      " 14  Vict Descent_F  964200 non-null  float64\n",
      " 15  Vict Descent_G  964200 non-null  float64\n",
      " 16  Vict Descent_H  964200 non-null  float64\n",
      " 17  Vict Descent_I  964200 non-null  float64\n",
      " 18  Vict Descent_J  964200 non-null  float64\n",
      " 19  Vict Descent_K  964200 non-null  float64\n",
      " 20  Vict Descent_L  964200 non-null  float64\n",
      " 21  Vict Descent_O  964200 non-null  float64\n",
      " 22  Vict Descent_P  964200 non-null  float64\n",
      " 23  Vict Descent_S  964200 non-null  float64\n",
      " 24  Vict Descent_U  964200 non-null  float64\n",
      " 25  Vict Descent_V  964200 non-null  float64\n",
      " 26  Vict Descent_W  964200 non-null  float64\n",
      " 27  Vict Descent_X  964200 non-null  float64\n",
      " 28  Vict Descent_Z  964200 non-null  float64\n",
      " 29  AgeStd          964200 non-null  float64\n",
      " 30  night-day       964200 non-null  int16  \n",
      " 31  day_name_1      964200 non-null  int8   \n",
      " 32  day_name_2      964200 non-null  int8   \n",
      " 33  day_name_3      964200 non-null  int8   \n",
      " 34  day_name_4      964200 non-null  int8   \n",
      " 35  day_name_5      964200 non-null  int8   \n",
      " 36  day_name_6      964200 non-null  int8   \n",
      " 37  month_name_1    964200 non-null  int8   \n",
      " 38  month_name_2    964200 non-null  int8   \n",
      " 39  month_name_3    964200 non-null  int8   \n",
      " 40  month_name_4    964200 non-null  int8   \n",
      " 41  month_name_5    964200 non-null  int8   \n",
      " 42  month_name_6    964200 non-null  int8   \n",
      " 43  month_name_7    964200 non-null  int8   \n",
      " 44  month_name_8    964200 non-null  int8   \n",
      " 45  month_name_9    964200 non-null  int8   \n",
      " 46  month_name_10   964200 non-null  int8   \n",
      " 47  month_name_11   964200 non-null  int8   \n",
      " 48  Status_1        964200 non-null  int8   \n",
      " 49  Status_2        964200 non-null  int8   \n",
      " 50  Status_3        964200 non-null  int8   \n",
      " 51  Status_4        964200 non-null  int8   \n",
      " 52  Status_5        964200 non-null  int8   \n",
      " 53  season_1        964200 non-null  int8   \n",
      " 54  season_2        964200 non-null  int8   \n",
      " 55  season_3        964200 non-null  int8   \n",
      " 56  season_4        964200 non-null  int8   \n",
      " 57  Region_1        964200 non-null  int8   \n",
      " 58  Region_2        964200 non-null  int8   \n",
      " 59  Region_3        964200 non-null  int8   \n",
      " 60  Region_4        964200 non-null  int8   \n",
      " 61  Region_5        964200 non-null  int8   \n",
      " 62  Region_6        964200 non-null  int8   \n",
      "dtypes: float64(25), int16(5), int8(33)\n",
      "memory usage: 230.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_pred_proba=None):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            # For multiclass ROC AUC\n",
    "            lb = LabelBinarizer()\n",
    "            y_true_bin = lb.fit_transform(y_true)\n",
    "            if y_pred_proba.shape[1] == 2:  # Binary classification\n",
    "                metrics['roc_auc'] = roc_auc_score(y_true_bin, y_pred_proba[:, 1])\n",
    "            else:  # Multi-class\n",
    "                metrics['roc_auc'] = roc_auc_score(\n",
    "                    y_true_bin, \n",
    "                    y_pred_proba,\n",
    "                    multi_class='ovr',\n",
    "                    average='weighted'\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not calculate ROC AUC: {str(e)}\")\n",
    "            metrics['roc_auc'] = None\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cross_validation(model, X, y, skf):\n",
    "    fold_metrics = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "        X_fold_train, X_fold_val = X[train_idx], X[val_idx]\n",
    "        y_fold_train, y_fold_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_fold_train_scaled = scaler.fit_transform(X_fold_train)\n",
    "        X_fold_val_scaled = scaler.transform(X_fold_val)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_fold_train_scaled, y_fold_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_fold_val_scaled)\n",
    "        \n",
    "        # Get prediction probabilities if the model supports it\n",
    "        try:\n",
    "            y_pred_proba = model.predict_proba(X_fold_val_scaled)\n",
    "        except:\n",
    "            y_pred_proba = None\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(y_fold_val, y_pred, y_pred_proba)\n",
    "        metrics['fold'] = fold\n",
    "        fold_metrics.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(fold_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_experiment(X_train, y_train, k_values=[3, 4, 5, 6, 7]):\n",
    "    knn_results = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        print(f\"\\nTraining KNN with k={k}\")\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        metrics_df = run_cross_validation(knn, X_train, y_train, skf)\n",
    "        \n",
    "        print(f\"\\nResults for k={k}:\")\n",
    "        print(metrics_df.mean())\n",
    "        knn_results[k] = metrics_df\n",
    "    \n",
    "    # Find best k based on mean f1 score\n",
    "    best_k = max(k_values, key=lambda k: knn_results[k]['f1'].mean())\n",
    "    return knn_results, best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nb_experiment(X_train, y_train):\n",
    "    print(\"\\nTraining Naive Bayes\")\n",
    "    nb = GaussianNB()\n",
    "    metrics_df = run_cross_validation(nb, X_train, y_train, skf)\n",
    "    \n",
    "    print(\"\\nNaive Bayes Results:\")\n",
    "    print(metrics_df.mean())\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lr_experiment(X_train, y_train):\n",
    "    print(\"\\nTraining Logistic Regression\")\n",
    "    lr = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "    metrics_df = run_cross_validation(lr, X_train, y_train, skf)\n",
    "    \n",
    "    print(\"\\nLogistic Regression Results:\")\n",
    "    print(metrics_df.mean())\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. SVM Implementation\n",
    "def run_svm_experiment(X_train, y_train, kernels=['linear', 'rbf'], C_values=[0.001, 0.01, 0.04]):\n",
    "    svm_results = {}\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        for C in C_values:\n",
    "            print(f\"\\nTraining SVM with kernel={kernel}, C={C}\")\n",
    "            svm = SVC(kernel=kernel, C=C, probability=True)\n",
    "            metrics_df = run_cross_validation(svm, X_train, y_train, skf)\n",
    "            \n",
    "            print(f\"\\nResults for kernel={kernel}, C={C}:\")\n",
    "            print(metrics_df.mean())\n",
    "            svm_results[(kernel, C)] = metrics_df\n",
    "    \n",
    "    # Find best combination based on mean f1 score\n",
    "    best_params = max(svm_results.keys(), key=lambda params: svm_results[params]['f1'].mean())\n",
    "    return svm_results, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.  DST\n",
    "\n",
    "\n",
    "def run_decision_tree_experiment(X_train, y_train, param_grid):\n",
    "    dt_results = {}\n",
    "    \n",
    "    # Buat kombinasi dari parameter grid\n",
    "    parameter_combinations = list(ParameterGrid(param_grid))\n",
    "    \n",
    "    for params in parameter_combinations:\n",
    "        print(f\"\\nTraining Decision Tree with params: {params}\")\n",
    "        dt = DecisionTreeClassifier(**params)\n",
    "        metrics_df = run_cross_validation(dt, X_train, y_train, skf)\n",
    "        \n",
    "        print(f\"\\nResults for params {params}:\")\n",
    "        print(metrics_df.mean())\n",
    "        dt_results[tuple(params.items())] = metrics_df\n",
    "    \n",
    "    # Cari parameter terbaik berdasarkan rata-rata f1-score\n",
    "    best_params = max(parameter_combinations, key=lambda p: dt_results[tuple(p.items())]['f1'].mean())\n",
    "    return dt_results, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_final_model(model, X_train, X_test, y_train, y_test):\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Get prediction probabilities if the model supports it\n",
    "    try:\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "    except:\n",
    "        y_pred_proba = None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    return calculate_metrics(y_test, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiments...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run experiments\n",
    "print(\"Starting experiments...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np  = np.array(y_test)\n",
    "X_test_np  = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== KNN Experiments ===\n",
      "\n",
      "Training KNN with k=3\n",
      "\n",
      "Results for k=3:\n",
      "accuracy     0.065739\n",
      "precision    0.089946\n",
      "recall       0.065739\n",
      "f1           0.060850\n",
      "roc_auc      0.563203\n",
      "fold         3.000000\n",
      "dtype: float64\n",
      "\n",
      "Training KNN with k=4\n",
      "\n",
      "Results for k=4:\n",
      "accuracy     0.064760\n",
      "precision    0.084431\n",
      "recall       0.064760\n",
      "f1           0.059352\n",
      "roc_auc      0.572446\n",
      "fold         3.000000\n",
      "dtype: float64\n",
      "\n",
      "Training KNN with k=5\n",
      "\n",
      "Results for k=5:\n",
      "accuracy     0.064997\n",
      "precision    0.083507\n",
      "recall       0.064997\n",
      "f1           0.059778\n",
      "roc_auc      0.579542\n",
      "fold         3.000000\n",
      "dtype: float64\n",
      "\n",
      "Training KNN with k=6\n",
      "\n",
      "Results for k=6:\n",
      "accuracy     0.064693\n",
      "precision    0.080701\n",
      "recall       0.064693\n",
      "f1           0.059618\n",
      "roc_auc      0.586135\n",
      "fold         3.000000\n",
      "dtype: float64\n",
      "\n",
      "Training KNN with k=7\n",
      "\n",
      "Results for k=7:\n",
      "accuracy     0.064288\n",
      "precision    0.078987\n",
      "recall       0.064288\n",
      "f1           0.059743\n",
      "roc_auc      0.591235\n",
      "fold         3.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# KNN\n",
    "print(\"\\n=== KNN Experiments ===\")\n",
    "knn_results, best_k = run_knn_experiment(X_train_np, y_train_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Test Set Evaluation ===\n",
      "\n",
      "Best KNN (k=3) Test Results:\n",
      "accuracy     0.068458\n",
      "precision    0.094780\n",
      "recall       0.068458\n",
      "f1           0.065743\n",
      "roc_auc      0.567444\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Final Test Set Evaluation ===\")\n",
    "\n",
    "# Best KNN\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_test_metrics = evaluate_final_model(best_knn, X_train_np, X_test_np, y_train_np, y_test_np)\n",
    "print(f\"\\nBest KNN (k={best_k}) Test Results:\")\n",
    "print(pd.Series(knn_test_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np  = np.array(y_test)\n",
    "X_test_np  = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Naive Bayes Experiments ===\n",
      "\n",
      "Training Naive Bayes\n",
      "\n",
      "Naive Bayes Results:\n",
      "accuracy     0.001823\n",
      "precision    0.904966\n",
      "recall       0.001823\n",
      "f1           0.000915\n",
      "roc_auc      0.668149\n",
      "fold         3.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Naive Bayes\n",
    "print(\"\\n=== Naive Bayes Experiments ===\")\n",
    "nb_results = run_nb_experiment(X_train_np, y_train_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Test Results:\n",
      "accuracy     0.001339\n",
      "precision    0.905119\n",
      "recall       0.001339\n",
      "f1           0.000788\n",
      "roc_auc      0.702213\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb_test_metrics = evaluate_final_model(nb, X_train_np, X_test_np, y_train_np, y_test_np)\n",
    "print(\"\\nNaive Bayes Test Results:\")\n",
    "print(pd.Series(nb_test_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np  = np.array(y_test)\n",
    "X_test_np  = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression Experiments ===\n",
      "\n",
      "Training Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results:\n",
      "accuracy     0.120505\n",
      "precision    0.141920\n",
      "recall       0.120505\n",
      "f1           0.091452\n",
      "roc_auc      0.807844\n",
      "fold         3.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "print(\"\\n=== Logistic Regression Experiments ===\")\n",
    "lr_results = run_lr_experiment(X_train_np, y_train_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Test Results:\n",
      "accuracy     0.121790\n",
      "precision    0.135841\n",
      "recall       0.121790\n",
      "f1           0.092942\n",
      "roc_auc      0.809247\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "lr_test_metrics = evaluate_final_model(lr, X_train_np, X_test_np, y_train_np, y_test_np)\n",
    "print(\"\\nLogistic Regression Test Results:\")\n",
    "print(pd.Series(lr_test_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np  = np.array(y_test)\n",
    "X_test_np  = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM Experiments ===\n",
      "\n",
      "Training SVM with kernel=linear, C=0.001\n",
      "\n",
      "Results for kernel=linear, C=0.001:\n",
      "accuracy     0.086167\n",
      "precision    0.276434\n",
      "recall       0.086167\n",
      "f1           0.057067\n",
      "roc_auc      0.803457\n",
      "fold         3.000000\n",
      "dtype: float64\n",
      "\n",
      "Training SVM with kernel=linear, C=0.01\n",
      "\n",
      "Results for kernel=linear, C=0.01:\n",
      "accuracy     0.118817\n",
      "precision    0.222301\n",
      "recall       0.118817\n",
      "f1           0.088552\n",
      "roc_auc      0.821574\n",
      "fold         3.000000\n",
      "dtype: float64\n",
      "\n",
      "Training SVM with kernel=linear, C=0.04\n",
      "\n",
      "Results for kernel=linear, C=0.04:\n",
      "accuracy     0.128744\n",
      "precision    0.206247\n",
      "recall       0.128744\n",
      "f1           0.098323\n",
      "roc_auc      0.826607\n",
      "fold         3.000000\n",
      "dtype: float64\n",
      "\n",
      "Training SVM with kernel=rbf, C=0.001\n",
      "\n",
      "Results for kernel=rbf, C=0.001:\n",
      "accuracy     0.081271\n",
      "precision    0.279513\n",
      "recall       0.081271\n",
      "f1           0.059888\n",
      "roc_auc      0.791724\n",
      "fold         3.000000\n",
      "dtype: float64\n",
      "\n",
      "Training SVM with kernel=rbf, C=0.01\n",
      "\n",
      "Results for kernel=rbf, C=0.01:\n",
      "accuracy     0.081271\n",
      "precision    0.279513\n",
      "recall       0.081271\n",
      "f1           0.059888\n",
      "roc_auc      0.792340\n",
      "fold         3.000000\n",
      "dtype: float64\n",
      "\n",
      "Training SVM with kernel=rbf, C=0.04\n",
      "\n",
      "Results for kernel=rbf, C=0.04:\n",
      "accuracy     0.085795\n",
      "precision    0.273302\n",
      "recall       0.085795\n",
      "f1           0.062664\n",
      "roc_auc      0.797355\n",
      "fold         3.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SVM\n",
    "print(\"\\n=== SVM Experiments ===\")\n",
    "svm_results, best_svm_params = run_svm_experiment(X_train_np, y_train_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Best SVM\n",
    "kernel, C = best_svm_params\n",
    "best_svm = SVC(kernel=kernel, C=C, probability=True)\n",
    "print(best_svm_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM with kernel=linear, C=0.04\n",
      "\n",
      "Results for kernel=linear, C=0.04:\n",
      "accuracy     0.128744\n",
      "precision    0.206247\n",
      "recall       0.128744\n",
      "f1           0.098323\n",
      "roc_auc      0.826580\n",
      "fold         3.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#saya ulang lagi karena best SVM awal tidak sengaja tersntuh yang mengharuskan saya melatih dan memrediksi SVC dengan parameter terbaik\n",
    "print(f\"\\nTraining SVM with kernel={kernel}, C={C}\")\n",
    "svm = SVC(kernel=kernel, C=C, probability=True)\n",
    "metrics_df = run_cross_validation(svm, X_train_np, y_train_np, skf)\n",
    "            \n",
    "print(f\"\\nResults for kernel={kernel}, C={C}:\")\n",
    "print(metrics_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best SVM (kernel=linear, C=0.04) Test Results:\n",
      "accuracy     0.128565\n",
      "precision    0.209660\n",
      "recall       0.128565\n",
      "f1           0.098737\n",
      "roc_auc      0.828337\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_test_metrics = evaluate_final_model(best_svm, X_train_np, X_test_np, y_train_np, y_test_np)\n",
    "print(f\"\\nBest SVM (kernel={kernel}, C={C}) Test Results:\")\n",
    "print(pd.Series(svm_test_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np  = np.array(y_test)\n",
    "X_test_np  = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [48,192],\n",
    "    'min_samples_split': [40, 80],\n",
    "    'min_samples_leaf': [40, 80],\n",
    "    'max_features': [ 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [40, 80],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DST Experiments ===\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 40}:\n",
      "accuracy    0.06503042\n",
      "precision   0.73125511\n",
      "recall      0.06503042\n",
      "f1          0.03374675\n",
      "roc_auc     0.74547104\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 80}:\n",
      "accuracy    0.06317281\n",
      "precision   0.73299568\n",
      "recall      0.06317281\n",
      "f1          0.03241038\n",
      "roc_auc     0.74506086\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 40}:\n",
      "accuracy    0.05682583\n",
      "precision   0.69543417\n",
      "recall      0.05682583\n",
      "f1          0.02942671\n",
      "roc_auc     0.70761083\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 80}:\n",
      "accuracy    0.07239072\n",
      "precision   0.69729937\n",
      "recall      0.07239072\n",
      "f1          0.03957405\n",
      "roc_auc     0.76774334\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 40}:\n",
      "accuracy    0.08339791\n",
      "precision   0.55136114\n",
      "recall      0.08339791\n",
      "f1          0.05595989\n",
      "roc_auc     0.77326799\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 80}:\n",
      "accuracy    0.07887405\n",
      "precision   0.54668957\n",
      "recall      0.07887405\n",
      "f1          0.05037495\n",
      "roc_auc     0.77265981\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 40}:\n",
      "accuracy    0.08582895\n",
      "precision   0.56037465\n",
      "recall      0.08582895\n",
      "f1          0.05577917\n",
      "roc_auc     0.77195330\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 80}:\n",
      "accuracy    0.08775357\n",
      "precision   0.53094440\n",
      "recall      0.08775357\n",
      "f1          0.05544025\n",
      "roc_auc     0.77639240\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 40}:\n",
      "accuracy    0.06091016\n",
      "precision   0.72008244\n",
      "recall      0.06091016\n",
      "f1          0.03103375\n",
      "roc_auc     0.72262059\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 80}:\n",
      "accuracy    0.05581255\n",
      "precision   0.72035940\n",
      "recall      0.05581255\n",
      "f1          0.02743490\n",
      "roc_auc     0.71872495\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 40}:\n",
      "accuracy    0.04960007\n",
      "precision   0.72158922\n",
      "recall      0.04960007\n",
      "f1          0.02433464\n",
      "roc_auc     0.69232662\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 80}:\n",
      "accuracy    0.06013376\n",
      "precision   0.70041929\n",
      "recall      0.06013376\n",
      "f1          0.03057532\n",
      "roc_auc     0.74533572\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 40}:\n",
      "accuracy    0.06330815\n",
      "precision   0.53957464\n",
      "recall      0.06330815\n",
      "f1          0.03923448\n",
      "roc_auc     0.72002696\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 80}:\n",
      "accuracy    0.07323502\n",
      "precision   0.52479519\n",
      "recall      0.07323502\n",
      "f1          0.04535269\n",
      "roc_auc     0.76103813\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 40}:\n",
      "accuracy    0.06459143\n",
      "precision   0.50522272\n",
      "recall      0.06459143\n",
      "f1          0.03952547\n",
      "roc_auc     0.72695130\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 48, 'max_features': 'log2', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 80}:\n",
      "accuracy    0.06452407\n",
      "precision   0.53010630\n",
      "recall      0.06452407\n",
      "f1          0.03954168\n",
      "roc_auc     0.74314887\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 40}:\n",
      "accuracy    0.08056184\n",
      "precision   0.71943403\n",
      "recall      0.08056184\n",
      "f1          0.04369364\n",
      "roc_auc     0.78105355\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 80}:\n",
      "accuracy    0.06857541\n",
      "precision   0.71623226\n",
      "recall      0.06857541\n",
      "f1          0.03820346\n",
      "roc_auc     0.73465721\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 40}:\n",
      "accuracy    0.06607764\n",
      "precision   0.67411807\n",
      "recall      0.06607764\n",
      "f1          0.03426048\n",
      "roc_auc     0.75347812\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 80}:\n",
      "accuracy    0.07191961\n",
      "precision   0.69985301\n",
      "recall      0.07191961\n",
      "f1          0.04014123\n",
      "roc_auc     0.74908671\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 40}:\n",
      "accuracy    0.06894637\n",
      "precision   0.55695823\n",
      "recall      0.06894637\n",
      "f1          0.04442079\n",
      "roc_auc     0.72791981\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 80}:\n",
      "accuracy    0.08424120\n",
      "precision   0.53700532\n",
      "recall      0.08424120\n",
      "f1          0.05678436\n",
      "roc_auc     0.77028251\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 40}:\n",
      "accuracy    0.07465290\n",
      "precision   0.54306908\n",
      "recall      0.07465290\n",
      "f1          0.04941472\n",
      "roc_auc     0.74101254\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 80, 'min_samples_split': 80}:\n",
      "accuracy    0.07559820\n",
      "precision   0.53254093\n",
      "recall      0.07559820\n",
      "f1          0.04539536\n",
      "roc_auc     0.75885373\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 40}:\n",
      "accuracy    0.05544131\n",
      "precision   0.69461797\n",
      "recall      0.05544131\n",
      "f1          0.02720064\n",
      "roc_auc     0.70950351\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 40, 'min_samples_split': 80}:\n",
      "accuracy    0.05398939\n",
      "precision   0.70623784\n",
      "recall      0.05398939\n",
      "f1          0.02478766\n",
      "roc_auc     0.70450969\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 40}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 40}:\n",
      "accuracy    0.05338110\n",
      "precision   0.69572345\n",
      "recall      0.05338110\n",
      "f1          0.02822966\n",
      "roc_auc     0.71855243\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 80}\n",
      "\n",
      "Results for params {'criterion': 'gini', 'max_depth': 192, 'max_features': 'log2', 'max_leaf_nodes': 40, 'min_samples_leaf': 80, 'min_samples_split': 80}:\n",
      "accuracy    0.05537412\n",
      "precision   0.70594044\n",
      "recall      0.05537412\n",
      "f1          0.02528525\n",
      "roc_auc     0.71397481\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training Decision Tree with params: {'criterion': 'gini', 'max_depth': 192, 'max_features': 'log2', 'max_leaf_nodes': 80, 'min_samples_leaf': 40, 'min_samples_split': 40}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[646], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DST\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== DST Experiments ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m dst_results, best_dst \u001b[38;5;241m=\u001b[39m \u001b[43mrun_decision_tree_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 20\u001b[0m, in \u001b[0;36mrun_decision_tree_experiment\u001b[1;34m(X_train, y_train, param_grid)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining Decision Tree with params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m dt \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m---> 20\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResults for params \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics_df\u001b[38;5;241m.\u001b[39mmean())\n",
      "Cell \u001b[1;32mIn[635], line 26\u001b[0m, in \u001b[0;36mrun_cross_validation\u001b[1;34m(model, X, y, skf)\u001b[0m\n\u001b[0;32m     23\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_fold_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_proba\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m fold\n\u001b[0;32m     28\u001b[0m fold_metrics\u001b[38;5;241m.\u001b[39mappend(metrics)\n",
      "Cell \u001b[1;32mIn[634], line 17\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[1;34m(y_true, y_pred, y_pred_proba)\u001b[0m\n\u001b[0;32m     15\u001b[0m         metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m roc_auc_score(y_true_bin, y_pred_proba[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Multi-class\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m         metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_true_bin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_pred_proba\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweighted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Could not calculate ROC AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:648\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    641\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    642\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m--> 648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\sklearn\\metrics\\_base.py:119\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    117\u001b[0m     y_true_c \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m    118\u001b[0m     y_score_c \u001b[38;5;241m=\u001b[39m y_score\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m--> 119\u001b[0m     score[c] \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Average the results\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:381\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_binary_roc_auc_score\u001b[39m(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_fpr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    380\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    383\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m         )\n\u001b[0;32m    387\u001b[0m     fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DST\n",
    "print(\"\\n=== DST Experiments ===\")\n",
    "dst_results, best_dst = run_decision_tree_experiment(X_train_np, y_train_np, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Test Results:\n",
      "{'criterion': 'gini', 'max_depth': 96, 'max_features': 'sqrt', 'max_leaf_nodes': 80, 'min_samples_leaf': 16, 'min_samples_split': 16}\n",
      "accuracy     0.119584\n",
      "precision    0.632982\n",
      "recall       0.119584\n",
      "f1           0.079751\n",
      "roc_auc      0.846931\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "best_dt = DecisionTreeClassifier(**best_dst)\n",
    "\n",
    "best_dt.fit(X_train, y_train)\n",
    "    \n",
    "dt_test_metrics = evaluate_final_model(best_dt, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    \n",
    "print(\"\\nDecision Tree Test Results:\")\n",
    "print(best_dst)\n",
    "print(pd.Series(dt_test_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Kasus khusus BPNN ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpnn(X_train, y_train, num_hidden_layers, num_neurons, learning_rate, epochs, activation_functions):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Menambahkan input layer dengan jumlah neuron sesuai num_neurons\n",
    "    model.add(tf.keras.layers.Dense(units=num_neurons, input_dim=X_train.shape[1], activation=activation_functions['hidden']))\n",
    "\n",
    "    # Menambahkan hidden layers\n",
    "    for _ in range(1, num_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(units=num_neurons, activation=activation_functions['hidden']))\n",
    "\n",
    "    # Menambahkan output layer dengan aktivasi softmax untuk multi-class\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation=activation_functions['output']))  # Jumlah kelas dari y_train yang sudah di-one-hot\n",
    "\n",
    "    # Kompilasi model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Melatih model\n",
    "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation_multilabel(model, X, y, n_splits=5, epochs=10):\n",
    "#     # Inisialisasi Multi-Label Stratified K-Fold\n",
    "#     mlskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "#     # DataFrame untuk menyimpan hasil metrik setiap fold\n",
    "#     metrics_df = pd.DataFrame(columns=['fold', 'accuracy', 'precision', 'recall', 'f1', 'auc_roc'])\n",
    "    \n",
    "#     for fold, (train_idx, val_idx) in enumerate(mlskf.split(X, y)):\n",
    "#         X_train, X_val = X[train_idx], X[val_idx]\n",
    "#         y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "#         # Train model pada data training\n",
    "#         model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "        \n",
    "#         # Prediksi pada data validation\n",
    "#         y_pred_proba = model.predict(X_val)  # Probabilitas\n",
    "#         y_pred = (y_pred_proba > 0.5).astype(int)  # Binarisasi prediksi\n",
    "        \n",
    "#         # Hitung metrik\n",
    "#         acc = accuracy_score(y_val, y_pred)\n",
    "#         prec = precision_score(y_val, y_pred, average='micro')\n",
    "#         rec = recall_score(y_val, y_pred, average='micro')\n",
    "#         f1 = f1_score(y_val, y_pred, average='micro')\n",
    "        \n",
    "#         # Menghitung AUC ROC untuk multi-label\n",
    "#         try:\n",
    "#             auc_roc = roc_auc_score(y_val, y_pred_proba, average='micro', multi_class='ovr')\n",
    "#         except ValueError:\n",
    "#             auc_roc = float('nan')  # Handle case di mana AUC ROC tidak bisa dihitung\n",
    "        \n",
    "#         # Simpan metrik pada setiap fold\n",
    "#         metrics_df = metrics_df.append({\n",
    "#             'fold': fold + 1,\n",
    "#             'accuracy': acc,\n",
    "#             'precision': prec,\n",
    "#             'recall': rec,\n",
    "#             'f1': f1,\n",
    "#             'auc_roc': auc_roc\n",
    "#         }, ignore_index=True)\n",
    "\n",
    "#     # Menampilkan rata-rata metrik dari seluruh fold\n",
    "#     print(\"\\nAverage Metrics Across Folds:\")\n",
    "#     print(metrics_df.mean())\n",
    "    \n",
    "#     return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. BPNN Implementation\n",
    "def run_bpp_experiment(X_train, y_train, hidden_layers, neurons, learning_rate, epochs, activation):\n",
    "    bpp_results = {}\n",
    "    \n",
    "    for hl in hidden_layers:\n",
    "        for n in neurons:\n",
    "            for lr in learning_rate:\n",
    "                for ep in epochs:\n",
    "                    for af in activation:\n",
    "                        # Konversi `af` menjadi dictionary agar sesuai dengan fungsi `bpnn`\n",
    "                        activation_functions = {'hidden': af[0], 'output': af[1]}\n",
    "                        \n",
    "                        print(f\"\\nTraining BPNN with hidden_layers={hl}, neurons={n}, lr={lr}, epochs={ep}, activation_functions={activation_functions}\")\n",
    "                        \n",
    "                        BPNN = bpnn(X_train, y_train, hl, n, lr, ep, activation_functions)\n",
    "                        \n",
    "                        metrics_df = run_cross_validation(BPNN, X_train, y_train, skf)\n",
    "                        \n",
    "                        print(f\"\\nResults for hidden_layers={hl}, neurons={n}, lr={lr}, epochs={ep}, activation_functions={activation_functions}:\")\n",
    "                        print(metrics_df.mean())\n",
    "                        \n",
    "                        bpp_results[(hl, n, lr, ep, tuple(af))] = metrics_df\n",
    "\n",
    "    best_bpp_params = max(bpp_results, key=lambda params: bpp_results[params]['f1'].mean())\n",
    "    return bpp_results, best_bpp_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inisialisasi encoder\n",
    "# encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# y_train_np = np.array(y_train)\n",
    "# y_test_np  = np.array(y_test)\n",
    "\n",
    "# # One-hot encoding untuk y_train dan y_test\n",
    "# y_train_onehot = encoder.fit_transform(y_train_np.reshape(-1, 1)).astype(np.int8)\n",
    "# y_test_onehot = encoder.transform(y_test_np.reshape(-1, 1)).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape y_train_onehot: (29617, 121)\n",
      "Shape y_test_onehot: (12694, 121)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape y_train_onehot:\", y_train_onehot.shape)\n",
    "print(\"Shape y_test_onehot:\", y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np  = np.array(y_test)\n",
    "X_test_np  = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.8f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BPNN Experiments ===\n",
      "\n",
      "Training BPNN with hidden_layers=1, neurons=32, lr=0.01, epochs=10, activation_functions={'hidden': 'relu', 'output': 'sigmoid'}\n",
      "741/741 [==============================] - 2s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "186/186 [==============================] - 1s 2ms/step\n",
      "741/741 [==============================] - 2s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "186/186 [==============================] - 0s 2ms/step\n",
      "741/741 [==============================] - 2s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "186/186 [==============================] - 0s 2ms/step\n",
      "741/741 [==============================] - 2s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "186/186 [==============================] - 0s 2ms/step\n",
      "741/741 [==============================] - 2s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "186/186 [==============================] - 0s 2ms/step\n",
      "\n",
      "Results for hidden_layers=1, neurons=32, lr=0.01, epochs=10, activation_functions={'hidden': 'relu', 'output': 'sigmoid'}:\n",
      "accuracy    0.00000000\n",
      "precision   0.00000000\n",
      "recall      0.00000000\n",
      "f1          0.00000000\n",
      "fold        3.00000000\n",
      "dtype: float64\n",
      "\n",
      "Training BPNN with hidden_layers=1, neurons=32, lr=0.01, epochs=10, activation_functions={'hidden': 'sigmoid', 'output': 'sigmoid'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== BPNN Experiments ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m params\u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_layers\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: [ [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m],  [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      9\u001b[0m }\n\u001b[1;32m---> 10\u001b[0m bpp_results, best_bpp_params \u001b[38;5;241m=\u001b[39m \u001b[43mrun_bpp_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_layers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneurons\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 15\u001b[0m, in \u001b[0;36mrun_bpp_experiment\u001b[1;34m(X_train, y_train, hidden_layers, neurons, learning_rate, epochs, activation)\u001b[0m\n\u001b[0;32m     11\u001b[0m activation_functions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden\u001b[39m\u001b[38;5;124m'\u001b[39m: af[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m: af[\u001b[38;5;241m1\u001b[39m]}\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining BPNN with hidden_layers=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, neurons=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, activation_functions=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactivation_functions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m BPNN \u001b[38;5;241m=\u001b[39m \u001b[43mbpnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_functions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m run_cross_validation(BPNN, X_train, y_train, skf)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResults for hidden_layers=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, neurons=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, activation_functions=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactivation_functions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 19\u001b[0m, in \u001b[0;36mbpnn\u001b[1;34m(X_train, y_train, num_hidden_layers, num_neurons, learning_rate, epochs, activation_functions)\u001b[0m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[0;32m     16\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Melatih model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\luxha\\anaconda3\\envs\\rapids\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 6 BPNN\n",
    "print(\"\\n=== BPNN Experiments ===\")\n",
    "params= {\n",
    "    'hidden_layers': [1, 2],\n",
    "    'neurons': [32, 64],\n",
    "    'learning_rate': [0.01, 0.001],\n",
    "    'epochs': [10, 100, 500],\n",
    "    'activation': [ ['relu',  'sigmoid'],  ['sigmoid',  'sigmoid']]\n",
    "}\n",
    "bpp_results, best_bpp_params = run_bpp_experiment(\n",
    "    X_train_np, \n",
    "    y_train_np,\n",
    "    params['hidden_layers'], \n",
    "    params['neurons'], \n",
    "    params['learning_rate'], \n",
    "    params['epochs'], \n",
    "    params['activation']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
